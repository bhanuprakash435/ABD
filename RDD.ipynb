{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Test RDD Examples\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDDs\n",
    "# Using parallelize method\n",
    "rdd_par = spark.sparkContext.parallelize([\"Hello World\", \"Hope you are not fed up with ABD class\", \"ello\"])\n",
    "type(rdd_par)\n",
    "rdd_par.collect()\n",
    "rdd_par.count()\n",
    "rdd_par.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello World', 'Hope you are not fed up with ABD class']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDD using transformations\n",
    "rdd_trans = rdd_par.filter(lambda word:word.startswith('H'))\n",
    "rdd_trans.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. \",\n",
       " '(See Duda & Hart, for example.) ',\n",
       " 'The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDD using Data Sources\n",
    "rdd_ds = spark.sparkContext.textFile('input.txt')\n",
    "rdd_ds.count()\n",
    "rdd_ds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 4),\n",
       " ('perhaps', 1),\n",
       " ('best', 1),\n",
       " ('known', 1),\n",
       " ('database', 1),\n",
       " ('in', 2),\n",
       " ('pattern', 1),\n",
       " (\"Fisher's\", 1),\n",
       " ('field', 1),\n",
       " ('referenced', 1),\n",
       " ('this', 1),\n",
       " ('', 2),\n",
       " ('Hart,', 1),\n",
       " ('example.)', 1),\n",
       " ('The', 1),\n",
       " ('set', 1),\n",
       " ('of', 2),\n",
       " ('50', 1),\n",
       " ('instances', 1),\n",
       " ('each,', 1),\n",
       " ('where', 1),\n",
       " ('class', 2),\n",
       " ('refers', 1),\n",
       " ('type', 1),\n",
       " ('plant.', 1),\n",
       " ('One', 1),\n",
       " ('linearly', 2),\n",
       " ('other', 1),\n",
       " ('2;', 1),\n",
       " ('latter', 1),\n",
       " ('are', 1),\n",
       " ('This', 1),\n",
       " ('the', 5),\n",
       " ('to', 3),\n",
       " ('be', 1),\n",
       " ('found', 1),\n",
       " ('recognition', 1),\n",
       " ('literature.', 1),\n",
       " ('paper', 1),\n",
       " ('a', 2),\n",
       " ('classic', 1),\n",
       " ('and', 1),\n",
       " ('frequently', 1),\n",
       " ('day.', 1),\n",
       " ('(See', 1),\n",
       " ('Duda', 1),\n",
       " ('&', 1),\n",
       " ('for', 1),\n",
       " ('data', 1),\n",
       " ('contains', 1),\n",
       " ('3', 1),\n",
       " ('classes', 1),\n",
       " ('each', 2),\n",
       " ('iris', 1),\n",
       " ('separable', 2),\n",
       " ('from', 2),\n",
       " ('NOT', 1),\n",
       " ('other.', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "freq_words = word_rdd.map(lambda word: (word, 1))\n",
    "freq_words.reduceByKey(lambda a, b: a + b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
